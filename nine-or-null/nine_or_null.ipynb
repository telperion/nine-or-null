{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "from pydub import AudioSegment\n",
    "\n",
    "import simfile\n",
    "from simfile.notes import NoteData, NoteType\n",
    "from simfile.timing import Beat, TimingData\n",
    "from simfile.timing.engine import TimingEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_simfile_dir = r\"C:\\Games\\ITGmania\\Songs\\ITGAlex's Compilation 4\\Fracture Ray\"\n",
    "\n",
    "test_audio_path = None\n",
    "test_simfile_path = None\n",
    "for f in os.listdir(test_simfile_dir):\n",
    "    if os.path.splitext(f)[1] in ['.ssc', '.sm']:\n",
    "        if (test_simfile_path is None) or (os.path.splitext(test_simfile_path)[1] == '.sm'):\n",
    "            test_simfile_path = os.path.join(test_simfile_dir, f)\n",
    "print(test_simfile_path)\n",
    "\n",
    "test_simfile = simfile.open(test_simfile_path)\n",
    "chart = test_simfile.charts[0]\n",
    "if not hasattr(chart, 'music') or chart.music is None:\n",
    "    test_audio_path = os.path.join(test_simfile_dir, test_simfile.music)\n",
    "else:\n",
    "    test_audio_path = os.path.join(test_simfile_dir, chart.music)\n",
    "print(test_audio_path)\n",
    "\n",
    "engine = TimingEngine(TimingData(test_simfile, chart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ext = os.path.splitext(test_audio_path)[1]\n",
    "audio = AudioSegment.from_file(test_audio_path, format=audio_ext[1:])\n",
    "audio_data = np.array(audio.get_array_of_samples())\n",
    "\n",
    "# https://stackoverflow.com/questions/53633177/how-to-read-a-mp3-audio-file-into-a-numpy-array-save-a-numpy-array-to-mp3\n",
    "if audio.channels == 2:\n",
    "    audio_data = audio_data.reshape((-1, 2))\n",
    "audio_data = audio_data / 2**15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(audio_data.shape)\n",
    "print(audio.frame_rate)\n",
    "\n",
    "# https://stackoverflow.com/questions/44787437/how-to-convert-a-wav-file-to-a-spectrogram-in-python3\n",
    "# https://stackoverflow.com/questions/47954034/plotting-spectrogram-in-audio-analysis\n",
    "window_ms = 5\n",
    "step_ms = 1\n",
    "eps = 1e-9\n",
    "\n",
    "nperseg = int(audio.frame_rate * window_ms * 1e-3)\n",
    "noverlap = nperseg - int(audio.frame_rate * step_ms * 1e-3)\n",
    "frequencies, times, spectrogram = signal.spectrogram(\n",
    "    audio_data[:, 0],\n",
    "    fs=audio.frame_rate,\n",
    "    window='hann',\n",
    "    nperseg=nperseg,\n",
    "    noverlap=noverlap,\n",
    "    detrend=False\n",
    ")\n",
    "# frequencies, times, spectrogram = signal.spectrogram(a, fs=1000)\n",
    "# print(spectrogram[:5, :5])\n",
    "splog = np.log2(spectrogram + eps)\n",
    "fig = plt.figure(figsize=(30, 6))\n",
    "plt.pcolormesh(times, frequencies, splog)\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fingerprint_sec = 0.10\n",
    "actual_step = (nperseg - noverlap) / audio.frame_rate\n",
    "fingerprint_size = 2 * int(0.5 * round(fingerprint_sec / actual_step))\n",
    "fingerprint_times = np.arange(-fingerprint_size // 2, fingerprint_size // 2) * actual_step\n",
    "frequency_emphasis_factor = 3000 # None\n",
    "\n",
    "# print(audio_data.shape)\n",
    "# print(frequencies.shape)\n",
    "# print(spectrogram.shape)\n",
    "# print(nperseg)\n",
    "# print(times[:5])\n",
    "# print(actual_step)\n",
    "# print(fingerprint_size)\n",
    "\n",
    "b = 0\n",
    "acc = np.zeros((frequencies.size, fingerprint_size))\n",
    "digest = np.zeros((0, fingerprint_size))\n",
    "while True:\n",
    "    t = engine.time_at(b)\n",
    "    b += 1\n",
    "    if (t < 0):\n",
    "        continue\n",
    "    if (t > audio.duration_seconds):\n",
    "        break\n",
    "\n",
    "    t_s = max(0,                   int(t / actual_step - fingerprint_size * 0.5))\n",
    "    t_f = min(audio_data.shape[0], int(t / actual_step + fingerprint_size * 0.5))\n",
    "    if (t_f - t_s != fingerprint_size):\n",
    "        # Not enough data at this beat tbh\n",
    "        continue\n",
    "    \n",
    "    # print(f'{t}: {t_s} -> {times[t_s]}, {t_f} -> {times[t_f]}')\n",
    "    frequency_weights = 1\n",
    "    if frequency_emphasis_factor is not None:\n",
    "        frequency_weights = np.tile(frequencies * np.exp(-frequencies / frequency_emphasis_factor), [fingerprint_size, 1]).T\n",
    "    spfilt = splog[:, t_s:t_f] * frequency_weights\n",
    "    acc += spfilt\n",
    "    digest = np.vstack([digest, np.sum(spfilt, axis=0)])\n",
    "\n",
    "    if b in []:\n",
    "        acc_log = splog[:, t_s:t_f]\n",
    "        fig = plt.figure(figsize=(6, 6))\n",
    "        plt.pcolormesh(fingerprint_times, frequencies, acc_log)\n",
    "        plt.ylabel('Frequency [Hz]')\n",
    "        plt.xlabel('Time [sec]')\n",
    "        plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 6))\n",
    "plt.pcolormesh(fingerprint_times, frequencies, acc)\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "plt.pcolormesh(fingerprint_times, np.arange(digest.shape[0]), digest)\n",
    "plt.ylabel('Beat Index')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loudest point of attack\n",
    "time_edge_kernel = [\n",
    "    [1, 3, 10, 3, 1],\n",
    "    [1, 3, 10, 3, 1],\n",
    "    [1, 3, 10, 3, 1],\n",
    "    [1, 3, 10, 3, 1],\n",
    "    [1, 3, 10, 3, 1]\n",
    "]\n",
    "time_edge_offset = 0.000\n",
    "if True:\n",
    "    # Leading edge of attack\n",
    "    time_edge_kernel = [\n",
    "        [1, 3, 10, 0, -10, -3, -1],\n",
    "        [1, 3, 10, 0, -10, -3, -1],\n",
    "        [1, 3, 10, 0, -10, -3, -1],\n",
    "        [1, 3, 10, 0, -10, -3, -1],\n",
    "        [1, 3, 10, 0, -10, -3, -1]\n",
    "    ]\n",
    "    time_edge_offset = 0.002\n",
    "\n",
    "acc_edge = signal.convolve2d(acc, time_edge_kernel, mode='same', boundary='wrap')\n",
    "# acc_edge = signal.convolve2d(digest, time_edge_kernel, mode='same', boundary='wrap')\n",
    "acc_edge_sum = np.sum(acc_edge, axis=0)\n",
    "fingerprint_times = np.arange(-fingerprint_size // 2, fingerprint_size // 2) * actual_step\n",
    "sync_bias = fingerprint_times[np.argmax(acc_edge_sum)] + time_edge_offset\n",
    "if abs(sync_bias - 0.009) < abs(sync_bias):\n",
    "    probable_bias = '+9ms'\n",
    "else:\n",
    "    probable_bias = 'null'\n",
    "\n",
    "simfile_artist = test_simfile.artisttranslit or test_simfile.artist\n",
    "simfile_title = test_simfile.titletranslit or test_simfile.title\n",
    "plot_title = f'Sync fingerprint for {simfile_artist} - \"{simfile_title}\"\\nDerived sync bias: {sync_bias:0.3f} (probably {probable_bias})'\n",
    "time_ticks = np.arange(-fingerprint_sec * 1000, fingerprint_sec * 1000, 10)\n",
    "print(time_ticks)\n",
    "\n",
    "print(f'Sync bias: {sync_bias:0.3f}')\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "plt.pcolormesh(fingerprint_times * 1e3, frequencies, acc)\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [msec]')\n",
    "plt.xticks(time_ticks)\n",
    "plt.plot(np.ones(np.shape(frequencies)) * sync_bias * 1e3, frequencies, 'r-')\n",
    "plt.title(plot_title)\n",
    "plt.show()\n",
    "fig.savefig(f'bias-freqdomain-{simfile_title}.png')\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "plt.pcolormesh(fingerprint_times * 1e3, np.arange(digest.shape[0]), digest)\n",
    "plt.ylabel('Beat Index')\n",
    "plt.xlabel('Time [msec]')\n",
    "plt.xticks(time_ticks)\n",
    "plt.plot(np.ones(np.shape(digest)[0]) * sync_bias * 1e3, np.arange(digest.shape[0]), 'r-')\n",
    "plt.title(plot_title)\n",
    "plt.show()\n",
    "fig.savefig(f'bias-beatdigest-{simfile_title}.png')\n",
    "\n",
    "acc_edge_sum = np.sum(acc_edge, axis=0)\n",
    "plt.plot(fingerprint_times, acc_edge_sum)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pack_dir = r\"C:\\Games\\ITGmania\\Songs\\ITGAlex's Compilation 4\"\n",
    "for d in os.listdir(pack_dir):\n",
    "    if os.path.isdir(os.path.join(pack_dir, d)):\n",
    "        print(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 3.14159265\n",
    "d = f'{a:0.3f}'\n",
    "print(d)\n",
    "b = '{:0.3f}'\n",
    "c = b.format(a)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_simfile_path in [\n",
    "    r'C:\\Games\\ITGmania\\Songs\\ephemera v0.2\\crew -All Hands on the Deck-\\crew.ssc',\n",
    "    r'C:\\Games\\ITGmania\\Songs\\ephemera v0.2\\PPBQ\\ppbq.ssc',\n",
    "    r'C:\\Games\\ITGmania\\Songs\\ephemera v0.2\\Adrenalina\\adrenalina.ssc'\n",
    "]:\n",
    "    base_simfile = simfile.open(test_simfile_path)\n",
    "    for chart_index, chart in enumerate(base_simfile.charts):\n",
    "        if any(k in chart for k in ['OFFSET', 'BPMS', 'STOPS', 'DELAYS', 'WARPS']):\n",
    "            print(f'{base_simfile.title}: {chart_index} ({chart.difficulty}) has split timing')\n",
    "\n",
    "    # for k, v in base_simfile.charts[1].items():\n",
    "    #     print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [None, 3]\n",
    "print(os.path.join(os.getcwd(), '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two aspects to confidence:\n",
    "# - is the overall max response a clear winner, or are there other contenders?\n",
    "#     - (second-highest - median) / (highest - median)\n",
    "# - is the response outside of the max tight, or does it have a lot of variance/noise?\n",
    "#     - stdev after scaling\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import glob\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "edge_discard = 3\n",
    "\n",
    "conv_list = glob.glob(r'C:\\Games\\ITGmania\\Songs\\ITL Online 2023\\__bias-check\\convolution-*.csv')\n",
    "\n",
    "conv_data = {}\n",
    "conv_results = []\n",
    "\n",
    "for i, f in enumerate(conv_list):\n",
    "    t = []\n",
    "    v = []\n",
    "    with open(f, 'r', encoding='ascii') as fp:\n",
    "        reader = csv.reader(fp)\n",
    "        for row in reader:\n",
    "            t += [float(row[0])]\n",
    "            v += [float(row[1])]\n",
    "    v_clip = v[edge_discard:-edge_discard]\n",
    "    v_clip = np.interp(v_clip, (min(v_clip), max(v_clip)), (0, 1))\n",
    "    t_clip = np.array(t[edge_discard:-edge_discard])\n",
    "    v_std = np.std(v_clip)\n",
    "    v_mean = np.mean(v_clip)\n",
    "    v_median = np.median(v_clip)\n",
    "    v_argmax = np.argmax(v_clip)\n",
    "    v_max = v_clip[v_argmax]\n",
    "    v_20 = np.percentile(v_clip, 20)\n",
    "    v_80 = np.percentile(v_clip, 80)\n",
    "\n",
    "    # Local maxima\n",
    "    v_moving_diff = v_clip[1:] - v_clip[:-1]\n",
    "    v_local_maxima = [i+1 for i, vmd in enumerate(zip(v_clip[:-2], v_clip[1:-1], v_clip[2:])) if (vmd[1] > vmd[0]) and (vmd[1] > vmd[2])]\n",
    "    v_peaks = sorted(zip(v_local_maxima, v_clip[v_local_maxima]), key=lambda x: x[1], reverse=True)[:6]\n",
    "    # print([f'{v[0]}: {v[1]}' for v in v_peaks])\n",
    "    N_SAMPLES_NOT_NEAR = 10\n",
    "    v_peaks_not_near = [v for v in v_peaks if abs(v[0] - v_peaks[0][0]) > N_SAMPLES_NOT_NEAR]\n",
    "    maxness = 0\n",
    "    if len(v_peaks_not_near) > 0:\n",
    "        maxness = (v_peaks_not_near[0][1] - v_median) / (v_peaks[0][1] - v_median)\n",
    "\n",
    "    # Another approach...\n",
    "    THEORETICAL_UPPER = 0.83\n",
    "    NEARNESS_SCALAR = 10    # milliseconds\n",
    "    NEARNESS_OFFSET = 0.5   # milliseconds\n",
    "    \n",
    "    v_max_check = np.vstack((np.zeros_like(v_clip), (v_clip - v_median) / (v_max - v_median)))\n",
    "    v_max_rivaling = np.max(v_max_check, axis=0)\n",
    "    t_close_check = np.vstack((np.zeros_like(t_clip), abs(t_clip - t_clip[v_argmax]) - NEARNESS_OFFSET)) / NEARNESS_SCALAR\n",
    "    t_close_enough = np.max(t_close_check, axis=0)\n",
    "    max_influence = np.power(v_max_rivaling, 4) * np.power(t_close_enough, 1.5)\n",
    "    total_max_influence = np.sum(max_influence) / np.size(max_influence)\n",
    "    confidence = min(1, (1 - np.power(total_max_influence, 0.2)) / THEORETICAL_UPPER)\n",
    "\n",
    "    print(f'{i:3d}/{len(conv_list):3d} {os.path.split(f)[1]:50s}: median = {v_median:0.6f}, stdev = {v_std:0.6f}, confidence = {confidence*100:0.2f}%')\n",
    "    conv_results.append((os.path.split(f)[1], confidence))\n",
    "\n",
    "    if confidence < 0.75 or i % 20 == 0:\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.title(os.path.split(f)[1] + f'\\nstdev = {v_std:0.6f}, iqr = {v_80-v_20:0.6f}, confidence = {confidence*100:0.2f}%')\n",
    "        # plt.plot(t[edge_discard:-edge_discard], v[edge_discard:-edge_discard])\n",
    "        # plt.plot(sorted(v_clip))\n",
    "        plt.plot(v_clip)\n",
    "        plt.plot(max_influence, 'm')\n",
    "        #plt.plot(v_max_rivaling, 'c')\n",
    "        # plt.plot(np.full_like(v_clip, v_mean + v_std*3), 'r')\n",
    "        # plt.plot(np.full_like(v_clip, v_mean),           'g')\n",
    "        # plt.plot(np.full_like(v_clip, v_mean - v_std*3), 'r')\n",
    "        plt.plot(np.full_like(v_clip, v_20),     'c')\n",
    "        plt.plot(np.full_like(v_clip, v_median), 'g')\n",
    "        plt.plot(np.full_like(v_clip, v_80),     'c')\n",
    "        #plt.plot([v[0] for v in v_peaks_not_near], [v[1] for v in v_peaks_not_near], 'k.')\n",
    "        plt.savefig(\"conf-\" + os.path.split(f)[1][12:-4] + \".png\")\n",
    "        plt.close()\n",
    "\n",
    "for v in sorted(conv_results, key=lambda v: v[1]):\n",
    "    print(f'{v[0]:50s}: {v[1]*100:0.2f}% confidence')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e370de9da903654768e066364e60adc850bb83526b434a3e92c9dc92a8fc08dd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('rhythm-analyzer-mTtypg5s-py3.9': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
