{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "from pydub import AudioSegment\n",
    "\n",
    "import simfile\n",
    "from simfile.notes import NoteData, NoteType\n",
    "from simfile.timing import Beat, TimingData\n",
    "from simfile.timing.engine import TimingEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_simfile_dir = r\"C:\\Games\\ITGmania\\Songs\\In The Groove Rebirth\\Cherry Blossom Whirlwind\"\n",
    "\n",
    "test_audio_path = None\n",
    "test_simfile_path = None\n",
    "for f in os.listdir(test_simfile_dir):\n",
    "    if os.path.splitext(f)[1] in ['.ssc', '.sm']:\n",
    "        if (test_simfile_path is None) or (os.path.splitext(test_simfile_path)[1] == '.sm'):\n",
    "            test_simfile_path = os.path.join(test_simfile_dir, f)\n",
    "print(test_simfile_path)\n",
    "\n",
    "test_simfile = simfile.open(test_simfile_path)\n",
    "chart = test_simfile.charts[0]\n",
    "if not hasattr(chart, 'music') or chart.music is None:\n",
    "    test_audio_path = os.path.join(test_simfile_dir, test_simfile.music)\n",
    "else:\n",
    "    test_audio_path = os.path.join(test_simfile_dir, chart.music)\n",
    "print(test_audio_path)\n",
    "\n",
    "engine = TimingEngine(TimingData(test_simfile, chart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ext = os.path.splitext(test_audio_path)[1]\n",
    "audio = AudioSegment.from_file(test_audio_path, format=audio_ext[1:])\n",
    "audio_data = np.array(audio.get_array_of_samples())\n",
    "\n",
    "# https://stackoverflow.com/questions/53633177/how-to-read-a-mp3-audio-file-into-a-numpy-array-save-a-numpy-array-to-mp3\n",
    "if audio.channels == 2:\n",
    "    audio_data = audio_data.reshape((-1, 2))\n",
    "audio_data = audio_data / 2**15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(audio_data.shape)\n",
    "print(audio.frame_rate)\n",
    "\n",
    "# https://stackoverflow.com/questions/44787437/how-to-convert-a-wav-file-to-a-spectrogram-in-python3\n",
    "# https://stackoverflow.com/questions/47954034/plotting-spectrogram-in-audio-analysis\n",
    "window_ms = 5\n",
    "step_ms = 1\n",
    "eps = 1e-9\n",
    "\n",
    "nperseg = int(audio.frame_rate * window_ms * 1e-3)\n",
    "noverlap = nperseg - int(audio.frame_rate * step_ms * 1e-3)\n",
    "frequencies, times, spectrogram = signal.spectrogram(\n",
    "    audio_data[:, 0],\n",
    "    fs=audio.frame_rate,\n",
    "    window='hann',\n",
    "    nperseg=nperseg,\n",
    "    noverlap=noverlap,\n",
    "    detrend=False\n",
    ")\n",
    "# frequencies, times, spectrogram = signal.spectrogram(a, fs=1000)\n",
    "# print(spectrogram[:5, :5])\n",
    "splog = np.log2(spectrogram + eps)\n",
    "fig = plt.figure(figsize=(30, 6))\n",
    "plt.pcolormesh(times, frequencies, splog)\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fingerprint_sec = 0.10\n",
    "actual_step = (nperseg - noverlap) / audio.frame_rate\n",
    "fingerprint_size = 2 * int(0.5 * round(fingerprint_sec / actual_step))\n",
    "fingerprint_times = np.arange(-fingerprint_size // 2, fingerprint_size // 2) * actual_step\n",
    "frequency_emphasis_factor = 3000 # None\n",
    "\n",
    "# print(audio_data.shape)\n",
    "# print(frequencies.shape)\n",
    "# print(spectrogram.shape)\n",
    "# print(nperseg)\n",
    "# print(times[:5])\n",
    "# print(actual_step)\n",
    "# print(fingerprint_size)\n",
    "\n",
    "b = 0\n",
    "acc = np.zeros((frequencies.size, fingerprint_size))\n",
    "digest = np.zeros((0, fingerprint_size))\n",
    "while True:\n",
    "    t = engine.time_at(b)\n",
    "    b += 1\n",
    "    if (t < 0):\n",
    "        continue\n",
    "    if (t > audio.duration_seconds):\n",
    "        break\n",
    "\n",
    "    t_s = max(0,                   int(t / actual_step - fingerprint_size * 0.5))\n",
    "    t_f = min(audio_data.shape[0], int(t / actual_step + fingerprint_size * 0.5))\n",
    "    if (t_f - t_s != fingerprint_size):\n",
    "        # Not enough data at this beat tbh\n",
    "        continue\n",
    "    \n",
    "    # print(f'{t}: {t_s} -> {times[t_s]}, {t_f} -> {times[t_f]}')\n",
    "    frequency_weights = 1\n",
    "    if frequency_emphasis_factor is not None:\n",
    "        frequency_weights = np.tile(frequencies * np.exp(-frequencies / frequency_emphasis_factor), [fingerprint_size, 1]).T\n",
    "    spfilt = splog[:, t_s:t_f] * frequency_weights\n",
    "    acc += spfilt\n",
    "    digest = np.vstack([digest, np.sum(spfilt, axis=0)])\n",
    "\n",
    "    if b in []:\n",
    "        acc_log = splog[:, t_s:t_f]\n",
    "        fig = plt.figure(figsize=(6, 6))\n",
    "        plt.pcolormesh(fingerprint_times, frequencies, acc_log)\n",
    "        plt.ylabel('Frequency [Hz]')\n",
    "        plt.xlabel('Time [sec]')\n",
    "        plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 6))\n",
    "plt.pcolormesh(fingerprint_times, frequencies, acc)\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "plt.pcolormesh(fingerprint_times, np.arange(digest.shape[0]), digest)\n",
    "plt.ylabel('Beat Index')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loudest point of attack\n",
    "time_edge_kernel = [\n",
    "    [1, 3, 10, 3, 1],\n",
    "    [1, 3, 10, 3, 1],\n",
    "    [1, 3, 10, 3, 1],\n",
    "    [1, 3, 10, 3, 1],\n",
    "    [1, 3, 10, 3, 1]\n",
    "]\n",
    "time_edge_offset = 0.000\n",
    "if True:\n",
    "    # Leading edge of attack\n",
    "    time_edge_kernel = [\n",
    "        [1, 3, 10, 0, -10, -3, -1],\n",
    "        [1, 3, 10, 0, -10, -3, -1],\n",
    "        [1, 3, 10, 0, -10, -3, -1],\n",
    "        [1, 3, 10, 0, -10, -3, -1],\n",
    "        [1, 3, 10, 0, -10, -3, -1]\n",
    "    ]\n",
    "    time_edge_offset = 0.002\n",
    "\n",
    "acc_edge = signal.convolve2d(acc, time_edge_kernel, mode='same', boundary='wrap')\n",
    "# acc_edge = signal.convolve2d(digest, time_edge_kernel, mode='same', boundary='wrap')\n",
    "acc_edge_sum = np.sum(acc_edge, axis=0)\n",
    "fingerprint_times = np.arange(-fingerprint_size // 2, fingerprint_size // 2) * actual_step\n",
    "sync_bias = fingerprint_times[np.argmax(acc_edge_sum)] + time_edge_offset\n",
    "if abs(sync_bias - 0.009) < abs(sync_bias):\n",
    "    probable_bias = '+9ms'\n",
    "else:\n",
    "    probable_bias = 'null'\n",
    "\n",
    "print(f'Sync bias: {sync_bias:0.3f}')\n",
    "\n",
    "plt.pcolormesh(fingerprint_times, frequencies, acc)\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.plot(np.ones(np.shape(frequencies)) * sync_bias, frequencies, 'r-')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "plt.pcolormesh(fingerprint_times, np.arange(digest.shape[0]), digest)\n",
    "plt.ylabel('Beat Index')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.plot(np.ones(np.shape(digest)[0]) * sync_bias, np.arange(digest.shape[0]), 'r-')\n",
    "plt.title(f'Sync fingerprint for {test_simfile.artist} - \"{test_simfile.title}\"\\nDerived sync bias: {sync_bias:0.3f} (probably {probable_bias})')\n",
    "plt.show()\n",
    "\n",
    "acc_edge_sum = np.sum(acc_edge, axis=0)\n",
    "plt.plot(fingerprint_times, acc_edge_sum)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e370de9da903654768e066364e60adc850bb83526b434a3e92c9dc92a8fc08dd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('rhythm-analyzer-mTtypg5s-py3.9': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
